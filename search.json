[
  {
    "objectID": "docs/how-to-guides/distributed_fcst_spark.html",
    "href": "docs/how-to-guides/distributed_fcst_spark.html",
    "title": "How to on Spark: Forecasting",
    "section": "",
    "text": "As long as Spark is installed and configured, TimeGPT will be able to use it. If executing on a distributed Spark cluster, make use the nixtlats library is installed across all the workers.\n\n\nTo run the forecasts distributed on Spark, just pass in a Spark DataFrame instead.\nInstantiate TimeGPT class.\n\nfrom nixtlats import TimeGPT\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nUse Spark as an engine.\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/11/08 02:44:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n23/11/08 02:44:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n\n\n\n\n\nurl_df = 'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv'\nspark_df = spark.createDataFrame(pd.read_csv(url_df))\nspark_df.show(5)\n\n                                                                                \n\n\n+---------+-------------------+-----+\n|unique_id|                 ds|    y|\n+---------+-------------------+-----+\n|       BE|2016-12-01 00:00:00| 72.0|\n|       BE|2016-12-01 01:00:00| 65.8|\n|       BE|2016-12-01 02:00:00|59.99|\n|       BE|2016-12-01 03:00:00|50.69|\n|       BE|2016-12-01 04:00:00|52.58|\n+---------+-------------------+-----+\nonly showing top 5 rows\n\n\n\n\nfcst_df = timegpt.forecast(spark_df, h=12)\nfcst_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...                        (4 + 16) / 20]\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...=============&gt;  (19 + 1) / 20]\n                                                                                \n\n\n+---------+-------------------+------------------+\n|unique_id|                 ds|           TimeGPT|\n+---------+-------------------+------------------+\n|       FR|2016-12-31 00:00:00|62.130218505859375|\n|       FR|2016-12-31 01:00:00|56.890830993652344|\n|       FR|2016-12-31 02:00:00| 52.23155212402344|\n|       FR|2016-12-31 03:00:00| 48.88866424560547|\n|       FR|2016-12-31 04:00:00| 46.49836730957031|\n+---------+-------------------+------------------+\nonly showing top 5 rows\n\n\n\n\n\n\nExogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\nFor example, if you’re forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\nTo incorporate exogenous variables in TimeGPT, you’ll need to pair each point in your time series data with the corresponding external data.\nLet’s see an example.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\nspark_df = spark.createDataFrame(df)\nspark_df.show(5)\n\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|unique_id|                 ds|    y|Exogenous1|Exogenous2|day_0|day_1|day_2|day_3|day_4|day_5|day_6|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|       BE|2016-12-01 00:00:00| 72.0|   61507.0|   71066.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 01:00:00| 65.8|   59528.0|   67311.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 02:00:00|59.99|   58812.0|   67470.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 03:00:00|50.69|   57676.0|   64529.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 04:00:00|52.58|   56804.0|   62773.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\nonly showing top 5 rows\n\n\n\nTo produce forecasts we have to add the future values of the exogenous variables. Let’s read this dataset. In this case we want to predict 24 steps ahead, therefore each unique id will have 24 observations.\n\nfuture_ex_vars_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv')\nspark_future_ex_vars_df = spark.createDataFrame(future_ex_vars_df)\nspark_future_ex_vars_df.show(5)\n\n+---------+-------------------+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|unique_id|                 ds|Exogenous1|Exogenous2|day_0|day_1|day_2|day_3|day_4|day_5|day_6|\n+---------+-------------------+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|       BE|2016-12-31 00:00:00|   64108.0|   70318.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 01:00:00|   62492.0|   67898.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 02:00:00|   61571.0|   68379.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 03:00:00|   60381.0|   64972.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 04:00:00|   60298.0|   62900.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n+---------+-------------------+----------+----------+-----+-----+-----+-----+-----+-----+-----+\nonly showing top 5 rows\n\n\n\nLet’s call the forecast method, adding this information:\n\ntimegpt_fcst_ex_vars_df = timegpt.forecast(df=spark_df, X_df=spark_future_ex_vars_df, h=24, level=[80, 90])\ntimegpt_fcst_ex_vars_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...                                      \nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...=============&gt;  (19 + 1) / 20]\n                                                                                \n\n\n+---------+-------------------+------------------+------------------+-----------------+-----------------+------------------+\n|unique_id|                 ds|           TimeGPT|     TimeGPT-lo-90|    TimeGPT-lo-80|    TimeGPT-hi-80|     TimeGPT-hi-90|\n+---------+-------------------+------------------+------------------+-----------------+-----------------+------------------+\n|       FR|2016-12-31 00:00:00| 64.97691027939692|60.056473801735784|61.71575274765864|68.23806781113521| 69.89734675705805|\n|       FR|2016-12-31 01:00:00| 60.14365519077404| 56.12626745731457|56.73784790927991|63.54946247226818| 64.16104292423351|\n|       FR|2016-12-31 02:00:00| 59.42375860682185| 54.84932824030574|56.52975776758845|62.31775944605525| 63.99818897333796|\n|       FR|2016-12-31 03:00:00| 55.11264928302748| 47.59671153125746|51.95117842731459|58.27412013874037|  62.6285870347975|\n|       FR|2016-12-31 04:00:00|54.400922806813526|44.925772896840385|49.65213255412798|59.14971305949907|63.876072716786666|\n+---------+-------------------+------------------+------------------+-----------------+-----------------+------------------+\nonly showing top 5 rows\n\n\n\n\nspark.stop()\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/distributed_fcst_spark.html#executing-on-spark",
    "href": "docs/how-to-guides/distributed_fcst_spark.html#executing-on-spark",
    "title": "How to on Spark: Forecasting",
    "section": "",
    "text": "To run the forecasts distributed on Spark, just pass in a Spark DataFrame instead.\nInstantiate TimeGPT class.\n\nfrom nixtlats import TimeGPT\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nUse Spark as an engine.\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/11/08 02:44:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n23/11/08 02:44:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n\n\n\n\n\nurl_df = 'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv'\nspark_df = spark.createDataFrame(pd.read_csv(url_df))\nspark_df.show(5)\n\n                                                                                \n\n\n+---------+-------------------+-----+\n|unique_id|                 ds|    y|\n+---------+-------------------+-----+\n|       BE|2016-12-01 00:00:00| 72.0|\n|       BE|2016-12-01 01:00:00| 65.8|\n|       BE|2016-12-01 02:00:00|59.99|\n|       BE|2016-12-01 03:00:00|50.69|\n|       BE|2016-12-01 04:00:00|52.58|\n+---------+-------------------+-----+\nonly showing top 5 rows\n\n\n\n\nfcst_df = timegpt.forecast(spark_df, h=12)\nfcst_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...                        (4 + 16) / 20]\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...=============&gt;  (19 + 1) / 20]\n                                                                                \n\n\n+---------+-------------------+------------------+\n|unique_id|                 ds|           TimeGPT|\n+---------+-------------------+------------------+\n|       FR|2016-12-31 00:00:00|62.130218505859375|\n|       FR|2016-12-31 01:00:00|56.890830993652344|\n|       FR|2016-12-31 02:00:00| 52.23155212402344|\n|       FR|2016-12-31 03:00:00| 48.88866424560547|\n|       FR|2016-12-31 04:00:00| 46.49836730957031|\n+---------+-------------------+------------------+\nonly showing top 5 rows\n\n\n\n\n\n\nExogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\nFor example, if you’re forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\nTo incorporate exogenous variables in TimeGPT, you’ll need to pair each point in your time series data with the corresponding external data.\nLet’s see an example.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\nspark_df = spark.createDataFrame(df)\nspark_df.show(5)\n\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|unique_id|                 ds|    y|Exogenous1|Exogenous2|day_0|day_1|day_2|day_3|day_4|day_5|day_6|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|       BE|2016-12-01 00:00:00| 72.0|   61507.0|   71066.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 01:00:00| 65.8|   59528.0|   67311.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 02:00:00|59.99|   58812.0|   67470.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 03:00:00|50.69|   57676.0|   64529.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 04:00:00|52.58|   56804.0|   62773.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\nonly showing top 5 rows\n\n\n\nTo produce forecasts we have to add the future values of the exogenous variables. Let’s read this dataset. In this case we want to predict 24 steps ahead, therefore each unique id will have 24 observations.\n\nfuture_ex_vars_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv')\nspark_future_ex_vars_df = spark.createDataFrame(future_ex_vars_df)\nspark_future_ex_vars_df.show(5)\n\n+---------+-------------------+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|unique_id|                 ds|Exogenous1|Exogenous2|day_0|day_1|day_2|day_3|day_4|day_5|day_6|\n+---------+-------------------+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|       BE|2016-12-31 00:00:00|   64108.0|   70318.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 01:00:00|   62492.0|   67898.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 02:00:00|   61571.0|   68379.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 03:00:00|   60381.0|   64972.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n|       BE|2016-12-31 04:00:00|   60298.0|   62900.0|  0.0|  0.0|  0.0|  0.0|  0.0|  1.0|  0.0|\n+---------+-------------------+----------+----------+-----+-----+-----+-----+-----+-----+-----+\nonly showing top 5 rows\n\n\n\nLet’s call the forecast method, adding this information:\n\ntimegpt_fcst_ex_vars_df = timegpt.forecast(df=spark_df, X_df=spark_future_ex_vars_df, h=24, level=[80, 90])\ntimegpt_fcst_ex_vars_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...                                      \nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...=============&gt;  (19 + 1) / 20]\n                                                                                \n\n\n+---------+-------------------+------------------+------------------+-----------------+-----------------+------------------+\n|unique_id|                 ds|           TimeGPT|     TimeGPT-lo-90|    TimeGPT-lo-80|    TimeGPT-hi-80|     TimeGPT-hi-90|\n+---------+-------------------+------------------+------------------+-----------------+-----------------+------------------+\n|       FR|2016-12-31 00:00:00| 64.97691027939692|60.056473801735784|61.71575274765864|68.23806781113521| 69.89734675705805|\n|       FR|2016-12-31 01:00:00| 60.14365519077404| 56.12626745731457|56.73784790927991|63.54946247226818| 64.16104292423351|\n|       FR|2016-12-31 02:00:00| 59.42375860682185| 54.84932824030574|56.52975776758845|62.31775944605525| 63.99818897333796|\n|       FR|2016-12-31 03:00:00| 55.11264928302748| 47.59671153125746|51.95117842731459|58.27412013874037|  62.6285870347975|\n|       FR|2016-12-31 04:00:00|54.400922806813526|44.925772896840385|49.65213255412798|59.14971305949907|63.876072716786666|\n+---------+-------------------+------------------+------------------+-----------------+-----------------+------------------+\nonly showing top 5 rows\n\n\n\n\nspark.stop()"
  },
  {
    "objectID": "docs/tutorials/anomaly_detection.html",
    "href": "docs/tutorials/anomaly_detection.html",
    "title": "Anomaly Detection",
    "section": "",
    "text": "Anomaly detection in time series data plays a pivotal role in numerous sectors including finance, healthcare, security, and infrastructure. In essence, time series data represents a sequence of data points indexed (or listed or graphed) in time order, often with equal intervals. As systems and processes become increasingly digitized and interconnected, the need to monitor and ensure their normal behavior grows proportionally. Detecting anomalies can indicate potential problems, malfunctions, or even malicious activities. By promptly identifying these deviations from the expected pattern, organizations can take preemptive measures, optimize processes, or protect resources. TimeGPT includes the detect_anomalies method to detect anomalies automatically.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nThe detect_anomalies method is designed to process a dataframe containing series and subsequently label each observation based on its anomalous nature. The method evaluates each observation of the input dataframe against its context within the series, using statistical measures to determine its likelihood of being an anomaly. By default, the method identifies anomalies based on a 99 percent prediction interval. Observations that fall outside this interval are considered anomalies. The resultant dataframe will feature an added label, anomaly, that is set to 1 for anomalous observations and 0 otherwise.\n\npm_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/peyton_manning.csv')\ntimegpt_anomalies_df = timegpt.detect_anomalies(pm_df, time_col='timestamp', target_col='value', freq='D')\ntimegpt_anomalies_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Anomaly Detector Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nanomaly\nTimeGPT-lo-99\nTimeGPT\nTimeGPT-hi-99\n\n\n\n\n0\n2008-01-10\n0\n6.936009\n8.224194\n9.512378\n\n\n1\n2008-01-11\n0\n6.863336\n8.151521\n9.439705\n\n\n2\n2008-01-12\n0\n6.839064\n8.127249\n9.415433\n\n\n3\n2008-01-13\n0\n7.629072\n8.917256\n10.205441\n\n\n4\n2008-01-14\n0\n7.714111\n9.002295\n10.290480\n\n\n\n\n\n\n\n\ntimegpt.plot(pm_df, \n             timegpt_anomalies_df,\n             time_col='timestamp', \n             target_col='value')\n\n\n\n\nWhile the default behavior of the detect_anomalies method is to operate using a 99 percent prediction interval, users have the flexibility to adjust this threshold to their requirements. This is achieved by modifying the level argument. Decreasing the value of the level argument will result in a narrower prediction interval, subsequently identifying more observations as anomalies. See the next example.\n\ntimegpt_anomalies_df = timegpt.detect_anomalies(pm_df, time_col='timestamp', target_col='value', freq='D', level=90)\ntimegpt.plot(pm_df, \n             timegpt_anomalies_df,\n             time_col='timestamp', \n             target_col='value')\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Anomaly Detector Endpoint...\n\n\n\n\n\nConversely, increasing the value will make prediction intervals larger, detecting fewer anomalies. This customization allows users to calibrate the sensitivity of the method to align with their specific use case, ensuring the most relevant and actionable insights are derived from the data.\n\ntimegpt_anomalies_df = timegpt.detect_anomalies(pm_df, time_col='timestamp', target_col='value', freq='D', level=99.99)\ntimegpt.plot(pm_df, \n             timegpt_anomalies_df,\n             time_col='timestamp', \n             target_col='value')\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Anomaly Detector Endpoint...\n\n\n\n\n\nYou can also include date_features to better detect anomalies:\n\ntimegpt_anomalies_df_x = timegpt.detect_anomalies(\n    pm_df, time_col='timestamp', \n    target_col='value', \n    freq='D', \n    date_features=True,\n    level=99.99,\n)\ntimegpt.plot(\n    pm_df, \n    timegpt_anomalies_df_x,\n    time_col='timestamp', \n    target_col='value',\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Anomaly Detector Endpoint...\n\n\n\n\n\n\nExogenous variables\nAdditionally you can pass exogenous variables to better inform TimeGPT about the data. You just simply have to add the exogenous regressors after the target column.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nExogenous1\nExogenous2\nday_0\nday_1\nday_2\nday_3\nday_4\nday_5\nday_6\n\n\n\n\n0\nBE\n2016-12-01 00:00:00\n72.00\n61507.0\n71066.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n1\nBE\n2016-12-01 01:00:00\n65.80\n59528.0\n67311.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\nBE\n2016-12-01 02:00:00\n59.99\n58812.0\n67470.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3\nBE\n2016-12-01 03:00:00\n50.69\n57676.0\n64529.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\nBE\n2016-12-01 04:00:00\n52.58\n56804.0\n62773.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\nNow let’s compute anomalies considering this information\n\ntimegpt_anomalies_df_x = timegpt.detect_anomalies(df=df)\ntimegpt.plot(\n    df, \n    timegpt_anomalies_df_x,\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Anomaly Detector Endpoint...\n\n\n\n\n\nWe can also explore the relative importance of each of the features.\n\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\nYou can also add special days for different countries:\n\nfrom nixtlats.date_features import CountryHolidays\n\n\ntimegpt_anomalies_df_x = timegpt.detect_anomalies(\n    df=df,\n    date_features=[CountryHolidays(countries=['FR'])]\n)\ntimegpt.plot(\n    df, \n    timegpt_anomalies_df_x,\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Anomaly Detector Endpoint...\n\n\n\n\n\n\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/historical_forecast.html",
    "href": "docs/tutorials/historical_forecast.html",
    "title": "Historical forecast",
    "section": "",
    "text": "Our time series model offers a powerful feature that allows users to retrieve historical forecasts alongside the prospective predictions. This functionality is accessible through the forecast method by setting the add_history=True argument.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nNow you can start to make forecasts! Let’s import an example:\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nvalue\n\n\n\n\n0\n1949-01-01\n112\n\n\n1\n1949-02-01\n118\n\n\n2\n1949-03-01\n132\n\n\n3\n1949-04-01\n129\n\n\n4\n1949-05-01\n121\n\n\n\n\n\n\n\n\ntimegpt.plot(df, time_col='timestamp', target_col='value')\n\n\n\n\nLet’s add fitted values. When add_history is set to True, the output DataFrame will include not only the future forecasts determined by the h argument, but also the historical predictions. Currently, the historical forecasts are not affected by h, and have a fix horizon depending on the frequency of the data. The historical forecasts are produced in a rolling window fashion, and concatenated.\n\ntimegpt_fcst_with_history_df = timegpt.forecast(\n    df=df, h=12, time_col='timestamp', target_col='value',\n    add_history=True,\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Calling Historical Forecast Endpoint...\n\n\n\ntimegpt_fcst_with_history_df.head()\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1951-01-01\n135.483673\n\n\n1\n1951-02-01\n144.442398\n\n\n2\n1951-03-01\n157.191910\n\n\n3\n1951-04-01\n148.769363\n\n\n4\n1951-05-01\n140.472946\n\n\n\n\n\n\n\nLet’s plot the results. This consolidated view of past and future predictions can be invaluable for understanding the model’s behavior and for evaluating its performance over time.\n\ntimegpt.plot(df, timegpt_fcst_with_history_df, time_col='timestamp', target_col='value')\n\n\n\n\nPlease note, however, that the initial values of the series are not included in these historical forecasts. This is because our model, TimeGPT, requires a certain number of initial observations to generate reliable forecasts. Therefore, while interpreting the output, it’s important to be aware that the first few observations serve as the basis for the model’s predictions and are not themselves predicted values.\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/cross_validation.html",
    "href": "docs/tutorials/cross_validation.html",
    "title": "Cross Validation",
    "section": "",
    "text": "One of the primary challenges in time series forecasting is the inherent uncertainty and variability over time, making it crucial to validate the accuracy and reliability of the models employed. Cross-validation, a robust model validation technique, is particularly adapted for this task, as it provides insights into the expected performance of a model on unseen data, ensuring the forecasts are reliable and resilient before being deployed in real-world scenarios.\nTimeGPT, understanding the intricate needs of time series forecasting, incorporates the cross_validation method, designed to streamline the validation process for time series models. This functionality enables practitioners to rigorously test their forecasting models against historical data, assessing their effectiveness while tuning them for optimal performance. This tutorial will guide you through the nuanced process of conducting cross-validation within the TimeGPT class, ensuring your time series forecasting models are not just well-constructed, but also validated for trustworthiness and precision.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nThe cross_validation method within the TimeGPT class is an advanced functionality crafted to perform systematic validation on time series forecasting models. This method necessitates a dataframe comprising time-ordered data and employs a rolling-window scheme to meticulously evaluate the model’s performance across different time periods, thereby ensuring the model’s reliability and stability over time.\nKey parameters include freq, which denotes the data’s frequency and is automatically inferred if not specified. The id_col, time_col, and target_col parameters designate the respective columns for each series’ identifier, time step, and target values. The method offers customization through parameters like n_windows, indicating the number of separate time windows on which the model is assessed, and step_size, determining the gap between these windows. If step_size is unspecified, it defaults to the forecast horizon h.\nThe process also allows for model refinement via finetune_steps, specifying the number of iterations for model fine-tuning on new data. Data pre-processing is manageable through clean_ex_first, deciding whether to cleanse the exogenous signal prior to forecasting. Additionally, the method supports enhanced feature engineering from time data through the date_features parameter, which can automatically generate crucial date-related features or accept custom functions for bespoke feature creation. The date_features_to_one_hot parameter further enables the transformation of categorical date features into a format suitable for machine learning models.\nIn execution, cross_validation assesses the model’s forecasting accuracy in each window, providing a robust view of the model’s performance variability over time and potential overfitting. This detailed evaluation ensures the forecasts generated are not only accurate but also consistent across diverse temporal contexts.\n\npm_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/peyton_manning.csv')\ntimegpt_cv_df = timegpt.cross_validation(\n    pm_df, \n    h=7, \n    n_windows=5, \n    time_col='timestamp', \n    target_col='value', \n    freq='D',\n)\ntimegpt_cv_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n\n\n\n\n\n\n\n\n\ntimestamp\ncutoff\nvalue\nTimeGPT\n\n\n\n\n0\n2015-12-17\n2015-12-16\n7.591862\n7.939553\n\n\n1\n2015-12-18\n2015-12-16\n7.528869\n7.887512\n\n\n2\n2015-12-19\n2015-12-16\n7.171657\n7.766617\n\n\n3\n2015-12-20\n2015-12-16\n7.891331\n7.931502\n\n\n4\n2015-12-21\n2015-12-16\n8.360071\n8.312632\n\n\n\n\n\n\n\n\nfrom IPython.display import display\n\n\ncutoffs = timegpt_cv_df['cutoff'].unique()\nfor cutoff in cutoffs:\n    fig = timegpt.plot(\n        pm_df.tail(100), \n        timegpt_cv_df.query('cutoff == @cutoff').drop(columns=['cutoff', 'value']),\n        time_col='timestamp', \n        target_col='value'\n    )\n    display(fig)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo asses the performance of TimeGPT with distributional forecasts, you can produce prediction intervals using the level argument.\n\ntimegpt_cv_df = timegpt.cross_validation(\n    pm_df, \n    h=7, \n    n_windows=5, \n    time_col='timestamp', \n    target_col='value', \n    freq='D',\n    level=[80, 90],\n)\ntimegpt_cv_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n\n\n\n\n\n\n\n\n\ntimestamp\ncutoff\nvalue\nTimeGPT\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\n2015-12-17\n2015-12-16\n7.591862\n7.939553\n7.564151\n7.675945\n8.203161\n8.314956\n\n\n1\n2015-12-18\n2015-12-16\n7.528869\n7.887512\n7.567342\n7.598298\n8.176726\n8.207681\n\n\n2\n2015-12-19\n2015-12-16\n7.171657\n7.766617\n7.146560\n7.266829\n8.266404\n8.386674\n\n\n3\n2015-12-20\n2015-12-16\n7.891331\n7.931502\n7.493021\n7.657075\n8.205929\n8.369982\n\n\n4\n2015-12-21\n2015-12-16\n8.360071\n8.312632\n7.017335\n7.446677\n9.178586\n9.607928\n\n\n\n\n\n\n\n\ncutoffs = timegpt_cv_df['cutoff'].unique()\nfor cutoff in cutoffs:\n    fig = timegpt.plot(\n        pm_df.tail(100), \n        timegpt_cv_df.query('cutoff == @cutoff').drop(columns=['cutoff', 'value']),\n        time_col='timestamp', \n        target_col='value',\n        level=[80, 90],\n        models=['TimeGPT']\n    )\n    display(fig)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can also include date_features to see their impact in forecasting accuracy:\n\ntimegpt_cv_df = timegpt.cross_validation(\n    pm_df, \n    h=7, \n    n_windows=5, \n    time_col='timestamp', \n    target_col='value', \n    freq='D',\n    level=[80, 90],\n    date_features=['month'],\n)\ntimegpt_cv_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n\n\n\n\n\n\n\n\n\ntimestamp\ncutoff\nvalue\nTimeGPT\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\n2015-12-17\n2015-12-16\n7.591862\n7.945311\n7.542366\n7.647852\n8.242769\n8.348255\n\n\n1\n2015-12-18\n2015-12-16\n7.528869\n7.892559\n7.271274\n7.481059\n8.304058\n8.513843\n\n\n2\n2015-12-19\n2015-12-16\n7.171657\n7.771581\n7.113544\n7.281711\n8.261451\n8.429619\n\n\n3\n2015-12-20\n2015-12-16\n7.891331\n7.939502\n6.988198\n7.345371\n8.533633\n8.890807\n\n\n4\n2015-12-21\n2015-12-16\n8.360071\n8.320170\n7.140163\n7.658314\n8.982027\n9.500178\n\n\n\n\n\n\n\n\ncutoffs = timegpt_cv_df['cutoff'].unique()\nfor cutoff in cutoffs:\n    fig = timegpt.plot(\n        pm_df.tail(100), \n        timegpt_cv_df.query('cutoff == @cutoff').drop(columns=['cutoff', 'value']),\n        time_col='timestamp', \n        target_col='value',\n        level=[80, 90],\n        models=['TimeGPT']\n    )\n    display(fig)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExogenous variables\nAdditionally you can pass exogenous variables to better inform TimeGPT about the data. You just simply have to add the exogenous regressors after the target column.\n\nY_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity.csv')\nX_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/exogenous-vars-electricity.csv')\ndf = Y_df.merge(X_df)\n\nNow let’s cross validate TimeGPT considering this information\n\ntimegpt_cv_df_x = timegpt.cross_validation(\n    df, \n    h=48, \n    n_windows=2,\n    level=[80, 90]\n)\ncutoffs = timegpt_cv_df_x.query('unique_id == \"BE\"')['cutoff'].unique()\nfor cutoff in cutoffs:\n    fig = timegpt.plot(\n        df.query('unique_id == \"BE\"').tail(24 * 7), \n        timegpt_cv_df_x.query('cutoff == @cutoff & unique_id == \"BE\"').drop(columns=['cutoff', 'y']),\n        models=['TimeGPT'],\n        level=[80, 90],\n    )\n    display(fig)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n\n\n\n\n\n\n\n\n\n\nCompare different models\nAlso, you can generate cross validation for different instances of TimeGPT using the model argument.\n\ntimegpt_cv_df_x_long_horizon = timegpt.cross_validation(\n    df, \n    h=48, \n    n_windows=2,\n    level=[80, 90],\n    model='timegpt-1-long-horizon',\n)\ntimegpt_cv_df_x_long_horizon.columns = timegpt_cv_df_x_long_horizon.columns.str.replace('TimeGPT', 'TimeGPT-LongHorizon')\ntimegpt_cv_df_x_models = timegpt_cv_df_x_long_horizon.merge(timegpt_cv_df_x)\ncutoffs = timegpt_cv_df_x_models.query('unique_id == \"BE\"')['cutoff'].unique()\nfor cutoff in cutoffs:\n    fig = timegpt.plot(\n        df.query('unique_id == \"BE\"').tail(24 * 7), \n        timegpt_cv_df_x_models.query('cutoff == @cutoff & unique_id == \"BE\"').drop(columns=['cutoff', 'y']),\n        models=['TimeGPT', 'TimeGPT-LongHorizon'],\n        level=[80, 90],\n    )\n    display(fig)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n\n\n\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/finetuning.html",
    "href": "docs/tutorials/finetuning.html",
    "title": "Finetuning",
    "section": "",
    "text": "Fine-tuning is a powerful process for utilizing TimeGPT more effectively. Foundation models are pre-trained on vast amounts of data, capturing wide-ranging features and patterns. These models can then be specialized for specific contexts or domains. With fine-tuning, the model’s parameters are refined to forecast a new task, allowing it to tailor its vast pre-existing knowledge toward the requirements of the new data. Fine-tuning thus serves as a crucial bridge, linking TimeGPT’s broad capabilities to your tasks specificities.\nConcretely, the process of fine-tuning consists of performing a certain number of training iterations on your input data minimizing the forecasting error. The forecasts will then be produced with the updated model. To control the number of iterations, use the finetune_steps argument of the forecast method.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nHere’s an example of how to fine-tune TimeGPT:\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nvalue\n\n\n\n\n0\n1949-01-01\n112\n\n\n1\n1949-02-01\n118\n\n\n2\n1949-03-01\n132\n\n\n3\n1949-04-01\n129\n\n\n4\n1949-05-01\n121\n\n\n\n\n\n\n\n\ntimegpt_fcst_finetune_df = timegpt.forecast(\n    df=df, h=12, finetune_steps=10,\n    time_col='timestamp', target_col='value',\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\ntimegpt.plot(\n    df, timegpt_fcst_finetune_df, \n    time_col='timestamp', target_col='value',\n)\n\n\n\n\nIn this code, finetune_steps=10 means the model will go through 10 iterations of training on your time series data.\nKeep in mind that fine-tuning can be a bit of trial and error. You might need to adjust the number of finetune_steps based on your specific needs and the complexity of your data. It’s recommended to monitor the model’s performance during fine-tuning and adjust as needed. Be aware that more finetune_steps may lead to longer training times and could potentially lead to overfitting if not managed properly.\nRemember, fine-tuning is a powerful feature, but it should be used thoughtfully and carefully.\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/exogenous_variables.html",
    "href": "docs/tutorials/exogenous_variables.html",
    "title": "Exogenous variables",
    "section": "",
    "text": "Exogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\nFor example, if you’re forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\nTo incorporate exogenous variables in TimeGPT, you’ll need to pair each point in your time series data with the corresponding external data.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nLet’s see an example on predicting day-ahead electricity prices. The following dataset contains the hourly electricity price (y column) for five markets in Europe and US, identified by the unique_id column. The columns from Exogenous1 to day_6 are exogenous variables that TimeGPT will use to predict the prices.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\nExogenous1\nExogenous2\nday_0\nday_1\nday_2\nday_3\nday_4\nday_5\nday_6\n\n\n\n\n0\nBE\n2016-12-01 00:00:00\n72.00\n61507.0\n71066.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n1\nBE\n2016-12-01 01:00:00\n65.80\n59528.0\n67311.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\nBE\n2016-12-01 02:00:00\n59.99\n58812.0\n67470.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n3\nBE\n2016-12-01 03:00:00\n50.69\n57676.0\n64529.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\nBE\n2016-12-01 04:00:00\n52.58\n56804.0\n62773.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\nTo produce forecasts we also have to add the future values of the exogenous variables. Let’s read this dataset. In this case, we want to predict 24 steps ahead, therefore each unique_id will have 24 observations.\n\nfuture_ex_vars_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-future-ex-vars.csv')\nfuture_ex_vars_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nExogenous1\nExogenous2\nday_0\nday_1\nday_2\nday_3\nday_4\nday_5\nday_6\n\n\n\n\n0\nBE\n2016-12-31 00:00:00\n64108.0\n70318.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\nBE\n2016-12-31 01:00:00\n62492.0\n67898.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\nBE\n2016-12-31 02:00:00\n61571.0\n68379.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\nBE\n2016-12-31 03:00:00\n60381.0\n64972.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\nBE\n2016-12-31 04:00:00\n60298.0\n62900.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\nLet’s call the forecast method, adding this information:\n\ntimegpt_fcst_ex_vars_df = timegpt.forecast(df=df, X_df=future_ex_vars_df, h=24, level=[80, 90])\ntimegpt_fcst_ex_vars_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\nunique_id\nds\nTimeGPT\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\nBE\n2016-12-31 00:00:00\n38.861762\n33.821073\n34.368669\n43.354854\n43.902450\n\n\n1\nBE\n2016-12-31 01:00:00\n35.382102\n30.014594\n31.493322\n39.270882\n40.749610\n\n\n2\nBE\n2016-12-31 02:00:00\n33.811425\n26.658821\n28.543087\n39.079764\n40.964029\n\n\n3\nBE\n2016-12-31 03:00:00\n31.707475\n24.896205\n26.818795\n36.596155\n38.518745\n\n\n4\nBE\n2016-12-31 04:00:00\n30.316475\n21.125143\n24.432148\n36.200801\n39.507807\n\n\n\n\n\n\n\n\ntimegpt.plot(\n    df[['unique_id', 'ds', 'y']], \n    timegpt_fcst_ex_vars_df, \n    max_insample_length=365, \n    level=[80, 90], \n)\n\n\n\n\nWe also can get the importance of the features.\n\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\nYou can also add country holidays using the CountryHolidays class.\n\nfrom nixtlats.date_features import CountryHolidays\n\n\ntimegpt_fcst_ex_vars_df = timegpt.forecast(\n    df=df, X_df=future_ex_vars_df, h=24, level=[80, 90], \n    date_features=[CountryHolidays(['US'])]\n)\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "distributed.timegpt.html",
    "href": "distributed.timegpt.html",
    "title": "Spark",
    "section": "",
    "text": "Give us a ⭐ on Github"
  },
  {
    "objectID": "distributed.timegpt.html#ray",
    "href": "distributed.timegpt.html#ray",
    "title": "Spark",
    "section": "Ray",
    "text": "Ray\n\nray.shutdown()"
  },
  {
    "objectID": "timegpt.html",
    "href": "timegpt.html",
    "title": "TimeGPT",
    "section": "",
    "text": "Give us a ⭐ on Github"
  },
  {
    "objectID": "timegpt.html#timegpt.validate_token",
    "href": "timegpt.html#timegpt.validate_token",
    "title": "TimeGPT",
    "section": "TimeGPT.validate_token",
    "text": "TimeGPT.validate_token\n\n TimeGPT.validate_token (log:bool=True)\n\nReturns True if your token is valid.\nNow you can start to make forecasts! Let’s import an example:"
  },
  {
    "objectID": "timegpt.html#timegpt.plot",
    "href": "timegpt.html#timegpt.plot",
    "title": "TimeGPT",
    "section": "TimeGPT.plot",
    "text": "TimeGPT.plot\n\n TimeGPT.plot (df:pandas.core.frame.DataFrame,\n               forecasts_df:Optional[pandas.core.frame.DataFrame]=None,\n               id_col:str='unique_id', time_col:str='ds',\n               target_col:str='y',\n               unique_ids:Union[List[str],NoneType,numpy.ndarray]=None,\n               plot_random:bool=True, models:Optional[List[str]]=None,\n               level:Optional[List[float]]=None,\n               max_insample_length:Optional[int]=None,\n               plot_anomalies:bool=False, engine:str='matplotlib',\n               resampler_kwargs:Optional[Dict]=None)\n\nPlot forecasts and insample values.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe DataFrame on which the function will operate. Expected to contain at least the following columns:- time_col: Column name in df that contains the time indices of the time series. This is typically a datetime column with regular intervals, e.g., hourly, daily, monthly data points.- target_col: Column name in df that contains the target variable of the time series, i.e., the variable we  wish to predict or analyze.Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:- id_col: Column name in df that identifies unique time series. Each unique value in this column corresponds to a unique time series.\n\n\nforecasts_df\nOptional\nNone\nDataFrame with columns [unique_id, ds] and models.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nunique_ids\nUnion\nNone\nTime Series to plot.If None, time series are selected randomly.\n\n\nplot_random\nbool\nTrue\nSelect time series to plot randomly.\n\n\nmodels\nOptional\nNone\nList of models to plot.\n\n\nlevel\nOptional\nNone\nList of prediction intervals to plot if paseed.\n\n\nmax_insample_length\nOptional\nNone\nMax number of train/insample observations to be plotted.\n\n\nplot_anomalies\nbool\nFalse\nPlot anomalies for each prediction interval.\n\n\nengine\nstr\nmatplotlib\nLibrary used to plot. ‘plotly’, ‘plotly-resampler’ or ‘matplotlib’.\n\n\nresampler_kwargs\nOptional\nNone\nKwargs to be passed to plotly-resampler constructor.For further custumization (“show_dash”) call the method,store the plotting object and add the extra arguments toits show_dash method."
  },
  {
    "objectID": "timegpt.html#timegpt.forecast",
    "href": "timegpt.html#timegpt.forecast",
    "title": "TimeGPT",
    "section": "TimeGPT.forecast",
    "text": "TimeGPT.forecast\n\n TimeGPT.forecast (df:pandas.core.frame.DataFrame, h:int,\n                   freq:Optional[str]=None, id_col:str='unique_id',\n                   time_col:str='ds', target_col:str='y',\n                   X_df:Optional[pandas.core.frame.DataFrame]=None,\n                   level:Optional[List[Union[int,float]]]=None,\n                   finetune_steps:int=0, clean_ex_first:bool=True,\n                   validate_token:bool=False, add_history:bool=False,\n                   date_features:Union[bool,List[str]]=False,\n                   date_features_to_one_hot:Union[bool,List[str]]=True,\n                   model:str='timegpt-1',\n                   num_partitions:Optional[int]=None)\n\nForecast your time series using TimeGPT.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe DataFrame on which the function will operate. Expected to contain at least the following columns:- time_col: Column name in df that contains the time indices of the time series. This is typically a datetime column with regular intervals, e.g., hourly, daily, monthly data points.- target_col: Column name in df that contains the target variable of the time series, i.e., the variable we  wish to predict or analyze.Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:- id_col: Column name in df that identifies unique time series. Each unique value in this column corresponds to a unique time series.\n\n\nh\nint\n\nForecast horizon.\n\n\nfreq\nOptional\nNone\nFrequency of the data. By default, the freq will be inferred automatically.See pandas’ available frequencies.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nX_df\nOptional\nNone\nDataFrame with [unique_id, ds] columns and df’s future exogenous.\n\n\nlevel\nOptional\nNone\nConfidence levels between 0 and 100 for prediction intervals.\n\n\nfinetune_steps\nint\n0\nNumber of steps used to finetune TimeGPT in thenew data.\n\n\nclean_ex_first\nbool\nTrue\nClean exogenous signal before making forecastsusing TimeGPT.\n\n\nvalidate_token\nbool\nFalse\nIf True, validates token before sending requests.\n\n\nadd_history\nbool\nFalse\nReturn fitted values of the model.\n\n\ndate_features\nUnion\nFalse\nFeatures computed from the dates. Can be pandas date attributes or functions that will take the dates as input.If True automatically adds most used date features for the frequency of df.\n\n\ndate_features_to_one_hot\nUnion\nTrue\nApply one-hot encoding to these date features.If date_features=True, then all date features areone-hot encoded by default.\n\n\nmodel\nstr\ntimegpt-1\nModel to use as a string. Options are: timegpt-1, and timegpt-1-long-horizon. We recommend using timegpt-1-long-horizon for forecasting if you want to predict more than one seasonal period given the frequency of your data.\n\n\nnum_partitions\nOptional\nNone\nNumber of partitions to use.Only used in distributed environments (spark, ray, dask).If None, the number of partitions will be equalto the available parallel resources.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with TimeGPT forecasts for point predictions and probabilisticpredictions (if level is not None)."
  },
  {
    "objectID": "timegpt.html#timegpt.cross_validation",
    "href": "timegpt.html#timegpt.cross_validation",
    "title": "TimeGPT",
    "section": "TimeGPT.cross_validation",
    "text": "TimeGPT.cross_validation\n\n TimeGPT.cross_validation (df:pandas.core.frame.DataFrame, h:int,\n                           freq:Optional[str]=None,\n                           id_col:str='unique_id', time_col:str='ds',\n                           target_col:str='y',\n                           level:Optional[List[Union[int,float]]]=None,\n                           validate_token:bool=False, n_windows:int=1,\n                           step_size:Optional[int]=None,\n                           finetune_steps:int=0, clean_ex_first:bool=True,\n                           date_features:Union[bool,List[str]]=False, date\n                           _features_to_one_hot:Union[bool,List[str]]=True\n                           , model:str='timegpt-1',\n                           num_partitions:Optional[int]=None)\n\nPerform cross validation in your time series using TimeGPT.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe DataFrame on which the function will operate. Expected to contain at least the following columns:- time_col: Column name in df that contains the time indices of the time series. This is typically a datetime column with regular intervals, e.g., hourly, daily, monthly data points.- target_col: Column name in df that contains the target variable of the time series, i.e., the variable we wish to predict or analyze.Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:- id_col: Column name in df that identifies unique time series. Each unique value in this column corresponds to a unique time series.\n\n\nh\nint\n\nForecast horizon.\n\n\nfreq\nOptional\nNone\nFrequency of the data. By default, the freq will be inferred automatically.See pandas’ available frequencies.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nlevel\nOptional\nNone\nConfidence level between 0 and 100 for detecting the anomalies.\n\n\nvalidate_token\nbool\nFalse\nIf True, validates token beforesending requests.\n\n\nn_windows\nint\n1\nNumber of windows to evaluate.\n\n\nstep_size\nOptional\nNone\nStep size between each cross validation window. If None it will be equal to h.\n\n\nfinetune_steps\nint\n0\nNumber of steps used to finetune TimeGPT in thenew data.\n\n\nclean_ex_first\nbool\nTrue\nClean exogenous signal before making forecastsusing TimeGPT.\n\n\ndate_features\nUnion\nFalse\nFeatures computed from the dates.Can be pandas date attributes or functions that will take the dates as input.If True automatically adds most used date features for thefrequency of df.\n\n\ndate_features_to_one_hot\nUnion\nTrue\nApply one-hot encoding to these date features.If date_features=True, then all date features areone-hot encoded by default.\n\n\nmodel\nstr\ntimegpt-1\nModel to use as a string. Options are: timegpt-1, and timegpt-1-long-horizon. We recommend using timegpt-1-long-horizon for forecasting if you want to predict more than one seasonal period given the frequency of your data.\n\n\nnum_partitions\nOptional\nNone\nNumber of partitions to use.Only used in distributed environments (spark, ray, dask).If None, the number of partitions will be equalto the available parallel resources.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with cross validation forecasts.\n\n\n\n\n# test pass dataframe with index\ndf_ds_index = df_.set_index('ds')[['unique_id', 'y']]\ndf_ds_index.index = pd.DatetimeIndex(df_ds_index.index)\nfcst_inferred_df_index = timegpt.forecast(df_ds_index, h=10)\nanom_inferred_df_index = timegpt.detect_anomalies(df_ds_index)\nfcst_inferred_df = timegpt.forecast(df_[['ds', 'unique_id', 'y']], h=10)\nanom_inferred_df = timegpt.detect_anomalies(df_[['ds', 'unique_id', 'y']])\npd.testing.assert_frame_equal(fcst_inferred_df_index, fcst_inferred_df, atol=1e-3)\npd.testing.assert_frame_equal(anom_inferred_df_index, anom_inferred_df, atol=1e-3)\ndf_ds_index = df_ds_index.groupby('unique_id').tail(80)\nfor freq in ['Y', 'W-MON', 'Q-DEC', 'H']:\n    df_ds_index.index = np.concatenate(\n        df_ds_index['unique_id'].nunique() * [pd.date_range(end='2023-01-01', periods=80, freq=freq)]\n    )\n    df_ds_index.index.name = 'ds'\n    fcst_inferred_df_index = timegpt.forecast(df_ds_index, h=10)\n    df_test = df_ds_index.reset_index()\n    fcst_inferred_df = timegpt.forecast(df_test, h=10)\n    pd.testing.assert_frame_equal(fcst_inferred_df_index, fcst_inferred_df, atol=1e-3)"
  },
  {
    "objectID": "timegpt.html#timegpt.detect_anomalies",
    "href": "timegpt.html#timegpt.detect_anomalies",
    "title": "TimeGPT",
    "section": "TimeGPT.detect_anomalies",
    "text": "TimeGPT.detect_anomalies\n\n TimeGPT.detect_anomalies (df:pandas.core.frame.DataFrame,\n                           freq:Optional[str]=None,\n                           id_col:str='unique_id', time_col:str='ds',\n                           target_col:str='y', level:Union[int,float]=99,\n                           clean_ex_first:bool=True,\n                           validate_token:bool=False,\n                           date_features:Union[bool,List[str]]=False, date\n                           _features_to_one_hot:Union[bool,List[str]]=True\n                           , model:str='timegpt-1',\n                           num_partitions:Optional[int]=None)\n\nDetect anomalies in your time series using TimeGPT.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nThe DataFrame on which the function will operate. Expected to contain at least the following columns:- time_col: Column name in df that contains the time indices of the time series. This is typically a datetime column with regular intervals, e.g., hourly, daily, monthly data points.- target_col: Column name in df that contains the target variable of the time series, i.e., the variable we  wish to predict or analyze.Additionally, you can pass multiple time series (stacked in the dataframe) considering an additional column:- id_col: Column name in df that identifies unique time series. Each unique value in this column corresponds to a unique time series.\n\n\nfreq\nOptional\nNone\nFrequency of the data. By default, the freq will be inferred automatically.See pandas’ available frequencies.\n\n\nid_col\nstr\nunique_id\nColumn that identifies each serie.\n\n\ntime_col\nstr\nds\nColumn that identifies each timestep, its values can be timestamps or integers.\n\n\ntarget_col\nstr\ny\nColumn that contains the target.\n\n\nlevel\nUnion\n99\nConfidence level between 0 and 100 for detecting the anomalies.\n\n\nclean_ex_first\nbool\nTrue\nClean exogenous signal before making forecastsusing TimeGPT.\n\n\nvalidate_token\nbool\nFalse\nIf True, validates token before sending requests.\n\n\ndate_features\nUnion\nFalse\nFeatures computed from the dates. Can be pandas date attributes or functions that will take the dates as input.If True automatically adds most used date features for the frequency of df.\n\n\ndate_features_to_one_hot\nUnion\nTrue\nApply one-hot encoding to these date features.If date_features=True, then all date features areone-hot encoded by default.\n\n\nmodel\nstr\ntimegpt-1\nModel to use as a string. Options are: timegpt-1, and timegpt-1-long-horizon. We recommend using timegpt-1-long-horizon for forecasting if you want to predict more than one seasonal period given the frequency of your data.\n\n\nnum_partitions\nOptional\nNone\nNumber of partitions to use.Only used in distributed environments (spark, ray, dask).If None, the number of partitions will be equalto the available parallel resources.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with anomalies flagged with 1 detected by TimeGPT."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TimeGPT",
    "section": "",
    "text": "pip install nixtlats\nGive us a ⭐ on Github"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "TimeGPT",
    "section": "",
    "text": "pip install nixtlats"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "TimeGPT",
    "section": "How to use",
    "text": "How to use\nJust import the library, set your credentials, and start forecasting in two lines of code!\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv')\n\nfrom nixtlats import TimeGPT\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\nfcst_df = timegpt.forecast(df, h=24, level=[80, 90])\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\ntimegpt.plot(df, fcst_df, level=[80, 90], max_insample_length=24 * 5)"
  },
  {
    "objectID": "date_features.html",
    "href": "date_features.html",
    "title": "Date Features",
    "section": "",
    "text": "Useful classes to generate date features and add them to TimeGPT.\n\n\nCountryHolidays\n\n CountryHolidays (countries:List[str])\n\nGiven a list of countries, returns a dataframe with holidays for each country.\n\nc_holidays = CountryHolidays(countries=['US', 'MX'])\nperiods = 365 * 5\ndates = pd.date_range(end='2023-09-01', periods=periods)\nholidays_df = c_holidays(dates)\nholidays_df.head()\n\n\n\n\n\n\n\n\nUS_New Year's Day\nUS_Martin Luther King Jr. Day\nUS_Washington's Birthday\nUS_Memorial Day\nUS_Independence Day\nUS_Labor Day\nUS_Columbus Day\nUS_Veterans Day\nUS_Veterans Day (Observed)\nUS_Thanksgiving\n...\nMX_Día de la Independencia [Independence Day]\nMX_Día de la Independencia [Independence Day] (Observed)\nMX_Día de la Revolución [Revolution Day] (Observed)\nMX_Día de la Revolución [Revolution Day]\nMX_Transmisión del Poder Ejecutivo Federal [Change of Federal Government]\nMX_Transmisión del Poder Ejecutivo Federal [Change of Federal Government] (Observed)\nMX_Navidad [Christmas]\nMX_Día de la Constitución [Constitution Day]\nMX_Año Nuevo [New Year's Day] (Observed)\nMX_Día del Trabajo [Labour Day] (Observed)\n\n\n\n\n2018-09-03\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2018-09-04\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2018-09-05\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2018-09-06\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2018-09-07\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows × 31 columns\n\n\n\n\n\n\nSpecialDates\n\n SpecialDates (special_dates:Dict[str,List[str]])\n\nGiven a dictionary of categories and dates, returns a dataframe with the special dates.\n\nspecial_dates = SpecialDates(\n    special_dates={\n        'Important Dates': ['2021-02-26', '2020-02-26'],\n        'Very Important Dates': ['2021-01-26', '2020-01-26', '2019-01-26']\n    }\n)\nperiods = 365 * 5\ndates = pd.date_range(end='2023-09-01', periods=periods)\nholidays_df = special_dates(dates)\nholidays_df.head()\n\n\n\n\n\n\n\n\nImportant Dates\nVery Important Dates\n\n\n\n\n2018-09-03\n0\n0\n\n\n2018-09-04\n0\n0\n\n\n2018-09-05\n0\n0\n\n\n2018-09-06\n0\n0\n\n\n2018-09-07\n0\n0\n\n\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/getting_started_short.html",
    "href": "docs/getting-started/getting_started_short.html",
    "title": "TimeGPT Quickstart",
    "section": "",
    "text": "Nixtla’s TimeGPT is a generative pre-trained forecasting model for time series data. TimeGPT can produce accurate forecasts for new time series without training, using only historical values as inputs. TimeGPT can be used across a plethora of tasks including demand forecasting, anomaly detection, financial forecasting, and more.\nThe TimeGPT model “reads” time series data much like the way humans read a sentence – from left to right. It looks at windows of past data, which we can think of as “tokens”, and predicts what comes next. This prediction is based on patterns the model identifies in past data and extrapolates into the future.\nThe API provides an interface to TimeGPT, allowing users to leverage its forecasting capabilities to predict future events. TimeGPT can also be used for other time series-related tasks, such as what-if scenarios, anomaly detection, and more.\n\n\n\nfigure\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/getting-started/getting_started_short.html#introduction",
    "href": "docs/getting-started/getting_started_short.html#introduction",
    "title": "TimeGPT Quickstart",
    "section": "",
    "text": "Nixtla’s TimeGPT is a generative pre-trained forecasting model for time series data. TimeGPT can produce accurate forecasts for new time series without training, using only historical values as inputs. TimeGPT can be used across a plethora of tasks including demand forecasting, anomaly detection, financial forecasting, and more.\nThe TimeGPT model “reads” time series data much like the way humans read a sentence – from left to right. It looks at windows of past data, which we can think of as “tokens”, and predicts what comes next. This prediction is based on patterns the model identifies in past data and extrapolates into the future.\nThe API provides an interface to TimeGPT, allowing users to leverage its forecasting capabilities to predict future events. TimeGPT can also be used for other time series-related tasks, such as what-if scenarios, anomaly detection, and more.\n\n\n\nfigure"
  },
  {
    "objectID": "docs/getting-started/getting_started_short.html#usage",
    "href": "docs/getting-started/getting_started_short.html#usage",
    "title": "TimeGPT Quickstart",
    "section": "Usage",
    "text": "Usage\n\nimport os\n\nfrom nixtlats import TimeGPT\n\nYou can instantiate the TimeGPT class providing your credentials.\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nYou can test the validate of your token calling the validate_token method:\n\ntimegpt.validate_token()\n\nINFO:nixtlats.timegpt:Happy Forecasting! :), If you have questions or need support, please email ops@nixtla.io\n\n\nTrue\n\n\nNow you can start making forecasts! Let’s import an example on the classic AirPassengers dataset. This dataset contains the monthly number of airline passengers in Australia between 1949 and 1960. First, let’s load the dataset and plot it:\n\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nvalue\n\n\n\n\n0\n1949-01-01\n112\n\n\n1\n1949-02-01\n118\n\n\n2\n1949-03-01\n132\n\n\n3\n1949-04-01\n129\n\n\n4\n1949-05-01\n121\n\n\n\n\n\n\n\n\ntimegpt.plot(df, time_col='timestamp', target_col='value')\n\n\n\n\n\n\n\n\n\n\nImportant requirements of the data\n\n\n\n\n\n\nMake sure the target variable column does not have missing or non-numeric values.\nDo not include gaps/jumps in the datestamps (for the given frequency) between the first and late datestamps. The forecast function will not impute missing dates.\nThe format of the datestamp column should be readable by Pandas (see this link for more details).\n\n\n\n\nNext, forecast the next 12 months using the SDK forecast method. Set the following parameters:\n\ndf: A pandas dataframe containing the time series data.\nh: The number of steps ahead to forecast.\nfreq: The frequency of the time series in Pandas format. See pandas’ available frequencies.\ntime_col: Column that identifies the datestamp column.\ntarget_col: The variable that we want to forecast.\n\n\ntimegpt_fcst_df = timegpt.forecast(df=df, h=12, freq='MS', time_col='timestamp', target_col='value')\ntimegpt_fcst_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1961-01-01\n437.837921\n\n\n1\n1961-02-01\n426.062714\n\n\n2\n1961-03-01\n463.116547\n\n\n3\n1961-04-01\n478.244507\n\n\n4\n1961-05-01\n505.646484\n\n\n\n\n\n\n\n\ntimegpt.plot(df, timegpt_fcst_df, time_col='timestamp', target_col='value')\n\n\n\n\nYou can also produce a longer forecasts increasing the horizon parameter. For example, let’s forecast the next 36 months:\n\ntimegpt_fcst_df = timegpt.forecast(df=df, h=36, time_col='timestamp', target_col='value', freq='MS')\ntimegpt_fcst_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1961-01-01\n437.837921\n\n\n1\n1961-02-01\n426.062714\n\n\n2\n1961-03-01\n463.116547\n\n\n3\n1961-04-01\n478.244507\n\n\n4\n1961-05-01\n505.646484\n\n\n\n\n\n\n\n\ntimegpt.plot(df, timegpt_fcst_df, time_col='timestamp', target_col='value')\n\n\n\n\nOr a shorter one:\n\ntimegpt_fcst_df = timegpt.forecast(df=df, h=6, time_col='timestamp', target_col='value', freq='MS')\ntimegpt.plot(df, timegpt_fcst_df, time_col='timestamp', target_col='value')\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nTimeGPT-1 is currently optimized for short horizon forecasting. While the forecast mehtod will allow any positive and large horizon, the accuracy of the forecasts might degrade. We are currently working to improve the accuracy on longer forecasts."
  },
  {
    "objectID": "docs/getting-started/getting_started_short.html#using-datetime-index-to-infer-frequency",
    "href": "docs/getting-started/getting_started_short.html#using-datetime-index-to-infer-frequency",
    "title": "TimeGPT Quickstart",
    "section": "Using DateTime index to infer frequency",
    "text": "Using DateTime index to infer frequency\nThe freq parameter, which indicates the time unit between consecutive data points, is particularly critical. Fortunately, you can pass a DataFrame with a DateTime index to the forecasting method, ensuring that your time series data is equipped with necessary temporal features. By assigning a suitable freq parameter to the DateTime index of a DataFrame, you inform the model about the consistent interval between observations — be it days (‘D’), months (‘M’), or another suitable frequency.\n\ndf_time_index = df.set_index('timestamp')\ndf_time_index.index = pd.DatetimeIndex(df_time_index.index, freq='MS')\ntimegpt.forecast(df=df, h=36, time_col='timestamp', target_col='value').head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Inferred freq: MS\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\n\n\n\n\n0\n1961-01-01\n437.837921\n\n\n1\n1961-02-01\n426.062714\n\n\n2\n1961-03-01\n463.116547\n\n\n3\n1961-04-01\n478.244507\n\n\n4\n1961-05-01\n505.646484"
  },
  {
    "objectID": "docs/tutorials/prediction_intervals.html",
    "href": "docs/tutorials/prediction_intervals.html",
    "title": "Prediction Intervals",
    "section": "",
    "text": "Prediction intervals provide a measure of the uncertainty in the forecasted values. In time series forecasting, a prediction interval gives an estimated range within which a future observation will fall, based on the level of confidence or uncertainty you set. This level of uncertainty is crucial for making informed decisions, risk assessments, and planning.\nFor instance, a 95% prediction interval means that 95 out of 100 times, the actual future value will fall within the estimated range. Therefore, a wider interval indicates greater uncertainty about the forecast, while a narrower interval suggests higher confidence.\nWhen using TimeGPT for time series forecasting, you have the option to set the level of prediction intervals according to your requirements. TimeGPT uses conformal prediction to calibrate the intervals.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nWhen using TimeGPT for time series forecasting, you can set the level (or levels) of prediction intervals according to your requirements. Here’s how you could do it:\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\ndf.head()\n\n\n\n\n\n\n\n\ntimestamp\nvalue\n\n\n\n\n0\n1949-01-01\n112\n\n\n1\n1949-02-01\n118\n\n\n2\n1949-03-01\n132\n\n\n3\n1949-04-01\n129\n\n\n4\n1949-05-01\n121\n\n\n\n\n\n\n\n\ntimegpt_fcst_pred_int_df = timegpt.forecast(\n    df=df, h=12, level=[80, 90, 99.7], \n    time_col='timestamp', target_col='value',\n)\ntimegpt_fcst_pred_int_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\nTimeGPT-lo-99.7\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\nTimeGPT-hi-99.7\n\n\n\n\n0\n1961-01-01\n437.837921\n415.826453\n423.783707\n431.987061\n443.688782\n451.892136\n459.849389\n\n\n1\n1961-02-01\n426.062714\n402.833523\n407.694061\n412.704926\n439.420502\n444.431366\n449.291904\n\n\n2\n1961-03-01\n463.116547\n423.434062\n430.316862\n437.412534\n488.820560\n495.916231\n502.799032\n\n\n3\n1961-04-01\n478.244507\n444.885193\n446.776764\n448.726837\n507.762177\n509.712250\n511.603821\n\n\n4\n1961-05-01\n505.646484\n465.736694\n471.976787\n478.409872\n532.883096\n539.316182\n545.556275\n\n\n\n\n\n\n\n\ntimegpt.plot(\n    df, timegpt_fcst_pred_int_df, \n    time_col='timestamp', target_col='value',\n    level=[80, 90],\n)\n\n\n\n\nIt’s essential to note that the choice of prediction interval level depends on your specific use case. For high-stakes predictions, you might want a wider interval to account for more uncertainty. For less critical forecasts, a narrower interval might be acceptable.\n\nHistorical Forecast\nYou can also compute prediction intervals for historical forecasts adding the add_history=True parameter as follows:\n\ntimegpt_fcst_pred_int_historical_df = timegpt.forecast(\n    df=df, h=12, level=[80, 90], \n    time_col='timestamp', target_col='value',\n    add_history=True,\n)\ntimegpt_fcst_pred_int_historical_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Calling Historical Forecast Endpoint...\n\n\n\n\n\n\n\n\n\ntimestamp\nTimeGPT\nTimeGPT-lo-80\nTimeGPT-lo-90\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\n1951-01-01\n135.483673\n111.937768\n105.262831\n159.029579\n165.704516\n\n\n1\n1951-02-01\n144.442398\n120.896493\n114.221556\n167.988304\n174.663241\n\n\n2\n1951-03-01\n157.191910\n133.646004\n126.971067\n180.737815\n187.412752\n\n\n3\n1951-04-01\n148.769363\n125.223458\n118.548521\n172.315269\n178.990206\n\n\n4\n1951-05-01\n140.472946\n116.927041\n110.252104\n164.018852\n170.693789\n\n\n\n\n\n\n\n\ntimegpt.plot(\n    df, timegpt_fcst_pred_int_historical_df, \n    time_col='timestamp', target_col='value',\n    level=[80, 90],\n)\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/holidays.html",
    "href": "docs/tutorials/holidays.html",
    "title": "Holidays and Special Dates",
    "section": "",
    "text": "Calendar variables and special dates are one of the most common types of exogenous variables used in forecasting applications. They provide additional context on the current state of the time series, especially for window-based models such as TimeGPT-1. These variables often include adding information on each observation’s month, week, day, or hour. For example, in high-frequency hourly data, providing the current month of the year provides more context than the limited history available in the input window to improve the forecasts.\nIn this tutorial we will show how to add calendar variables automatically to a dataset using the date_features function.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nGiven the predominance usage of calendar variables, we included an automatic creation of common calendar variables to the forecast method as a pre-processing step. To automatically add calendar variables, use the date_features argument.\n\npltr_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/openbb/pltr.csv')\n\n\nfcst_pltr_calendar_df = timegpt.forecast(\n    df=pltr_df.tail(2 * 14), h=14, freq='B',\n    time_col='date', target_col='Close',\n    date_features=['month','weekday']\n)\nfcst_pltr_calendar_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\n\n\n\n\n\n\ndate\nTimeGPT\n\n\n\n\n0\n2023-09-25\n14.790440\n\n\n1\n2023-09-26\n14.980692\n\n\n2\n2023-09-27\n15.161821\n\n\n3\n2023-09-28\n14.490647\n\n\n4\n2023-09-29\n14.354399\n\n\n\n\n\n\n\n\ntimegpt.plot(\n    pltr_df, \n    fcst_pltr_calendar_df, \n    id_col='series_id',\n    time_col='date',\n    target_col='Close',\n    max_insample_length=90,\n)\n\n\n\n\nWe can also plot the importance of each of the date features:\n\ntimegpt.weights_x.plot.barh(x='features', y='weights', figsize=(10, 10))\n\n&lt;AxesSubplot:ylabel='features'&gt;\n\n\n\n\n\nYou can also add country holidays using the CountryHolidays class.\n\nfrom nixtlats.date_features import CountryHolidays\n\n\nfcst_pltr_calendar_df = timegpt.forecast(\n    df=pltr_df, h=14, freq='B',\n    time_col='date', target_col='Close',\n    date_features=[CountryHolidays(['US'])]\n)\ntimegpt.weights_x.plot.barh(x='features', y='weights', figsize=(10, 10))\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n&lt;AxesSubplot:ylabel='features'&gt;\n\n\n\n\n\nHere’s a breakdown of how the date_features parameter works:\n\ndate_features (bool or list of str or callable): This parameter specifies which date attributes to consider.\n\nIf set to True, the model will automatically add the most common date features related to the frequency of the given dataframe (df). For a daily frequency, this could include features like day of the week, month, and year.\nIf provided a list of strings, it will consider those specific date attributes. For example, date_features=['weekday', 'month'] will only add the day of the week and month as features.\nIf provided a callable, it should be a function that takes dates as input and returns the desired feature. This gives flexibility in computing custom date features.\n\ndate_features_to_one_hot (bool or list of str): After determining the date features, one might want to one-hot encode them, especially if they are categorical in nature (like weekdays). One-hot encoding transforms these categorical features into a binary matrix, making them more suitable for many machine learning algorithms.\n\nIf date_features=True, then by default, all computed date features will be one-hot encoded.\nIf provided a list of strings, only those specific date features will be one-hot encoded.\n\n\nBy leveraging the date_features and date_features_to_one_hot parameters, one can efficiently incorporate the temporal effects of date attributes into their forecasting model, potentially enhancing its accuracy and interpretability.\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/multiple_series.html",
    "href": "docs/tutorials/multiple_series.html",
    "title": "Multiple Series",
    "section": "",
    "text": "TimeGPT provides a robust solution for multi-series forecasting, which involves analyzing multiple data series concurrently, rather than a single one. The tool can be fine-tuned using a broad collection of series, enabling you to tailor the model to suit your specific needs or tasks.\n\nimport os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nThe following dataset contains prices of different electricity markets. Let see how can we forecast them. The main argument of the forecast method is the input data frame with the historical values of the time series you want to forecast. This data frame can contain information from many time series. Use the unique_id column to identify the different time series of your dataset.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv')\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nBE\n2016-12-01 00:00:00\n72.00\n\n\n1\nBE\n2016-12-01 01:00:00\n65.80\n\n\n2\nBE\n2016-12-01 02:00:00\n59.99\n\n\n3\nBE\n2016-12-01 03:00:00\n50.69\n\n\n4\nBE\n2016-12-01 04:00:00\n52.58\n\n\n\n\n\n\n\nLet’s plot this series using StatsForecast:\n\ntimegpt.plot(df)\n\n\n\n\nWe just have to pass the dataframe to create forecasts for all the time series at once.\n\ntimegpt_fcst_multiseries_df = timegpt.forecast(df=df, h=24, level=[80, 90])\ntimegpt_fcst_multiseries_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\n\n\n\n\n\n\nunique_id\nds\nTimeGPT\nTimeGPT-lo-90\nTimeGPT-lo-80\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\nBE\n2016-12-31 00:00:00\n46.151176\n36.660475\n38.337019\n53.965334\n55.641878\n\n\n1\nBE\n2016-12-31 01:00:00\n42.426601\n31.602235\n33.976728\n50.876475\n53.250968\n\n\n2\nBE\n2016-12-31 02:00:00\n40.242889\n30.439970\n33.634985\n46.850794\n50.045809\n\n\n3\nBE\n2016-12-31 03:00:00\n38.265339\n26.841481\n31.022096\n45.508582\n49.689197\n\n\n4\nBE\n2016-12-31 04:00:00\n36.618801\n18.541384\n27.981348\n45.256255\n54.696218\n\n\n\n\n\n\n\n\ntimegpt.plot(df, timegpt_fcst_multiseries_df, max_insample_length=365, level=[80, 90])\n\n\n\n\n\nHistorical forecast\nYou can also compute prediction intervals for historical forecasts adding the add_history=True parameter as follows:\n\ntimegpt_fcst_multiseries_with_history_df = timegpt.forecast(df=df, h=24, level=[80, 90], add_history=True)\ntimegpt_fcst_multiseries_with_history_df.head()\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Calling Historical Forecast Endpoint...\n\n\n\n\n\n\n\n\n\nunique_id\nds\nTimeGPT\nTimeGPT-lo-80\nTimeGPT-lo-90\nTimeGPT-hi-80\nTimeGPT-hi-90\n\n\n\n\n0\nBE\n2016-12-06 00:00:00\n55.756317\n42.066461\n38.185578\n69.446173\n73.327057\n\n\n1\nBE\n2016-12-06 01:00:00\n52.820198\n39.130342\n35.249458\n66.510054\n70.390938\n\n\n2\nBE\n2016-12-06 02:00:00\n46.851070\n33.161215\n29.280331\n60.540926\n64.421810\n\n\n3\nBE\n2016-12-06 03:00:00\n50.640884\n36.951029\n33.070145\n64.330740\n68.211624\n\n\n4\nBE\n2016-12-06 04:00:00\n52.420403\n38.730547\n34.849663\n66.110258\n69.991142\n\n\n\n\n\n\n\n\ntimegpt.plot(\n    df, \n    timegpt_fcst_multiseries_with_history_df.groupby('unique_id').tail(365 + 24), \n    max_insample_length=365, \n    level=[80, 90],\n)\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/tutorials/irregular_timestamps.html",
    "href": "docs/tutorials/irregular_timestamps.html",
    "title": "Forecasting Time Series with Irregular Timestamps",
    "section": "",
    "text": "import os\n\nimport pandas as pd\nfrom nixtlats import TimeGPT\n\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nThe first step is to fetch your time series data. The data must include timestamps and the associated values. For instance, you might be working with stock prices, and your data could look something like the following. In this example we use OpenBB.\n\npltr_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/openbb/pltr.csv')\npltr_df['date'] = pd.to_datetime(pltr_df['date'])\n\n\npltr_df.head()\n\n\n\n\n\n\n\n\ndate\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nDividends\nStock Splits\n\n\n\n\n0\n2020-09-30\n10.00\n11.41\n9.11\n9.50\n9.50\n338584400\n0.0\n0.0\n\n\n1\n2020-10-01\n9.69\n10.10\n9.23\n9.46\n9.46\n124297600\n0.0\n0.0\n\n\n2\n2020-10-02\n9.06\n9.28\n8.94\n9.20\n9.20\n55018300\n0.0\n0.0\n\n\n3\n2020-10-05\n9.43\n9.49\n8.92\n9.03\n9.03\n36316900\n0.0\n0.0\n\n\n4\n2020-10-06\n9.04\n10.18\n8.90\n9.90\n9.90\n90864000\n0.0\n0.0\n\n\n\n\n\n\n\nLet’s see that this dataset has irregular timestamps. The dayofweek attribute from pandas’ DatetimeIndex returns the day of the week with Monday=0, Sunday=6. So, checking if dayofweek &gt; 4 is essentially checking if the date falls on a Saturday (5) or Sunday (6), which are typically non-business days (weekends).\n\n(pltr_df['date'].dt.dayofweek &gt; 4).sum()\n\n0\n\n\nAs we can see the timestamp is irregular. Let’s inspect the Close series.\n\ntimegpt.plot(pltr_df, time_col='date', target_col='Close')\n\n\n\n\nTo forecast this data, you can use our forecast method. Importantly, remember to specify the frequency of the data using the freq argument. In this case, it would be ‘B’ for business days. We also need to define the time_col to select the index of the series (by default is ds), and the target_col to forecast our target variable, in this case we will forecast Close:\n\nfcst_pltr_df = timegpt.forecast(\n    df=pltr_df, h=14, freq='B',\n    time_col='date', target_col='Close',\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\nfcst_pltr_df.head()\n\n\n\n\n\n\n\n\ndate\nTimeGPT\n\n\n\n\n0\n2023-09-25\n14.365891\n\n\n1\n2023-09-26\n14.460796\n\n\n2\n2023-09-27\n14.413015\n\n\n3\n2023-09-28\n14.488708\n\n\n4\n2023-09-29\n14.470786\n\n\n\n\n\n\n\nRemember, for business days, the frequency is ‘B’. For other frequencies, you can refer to the pandas offset aliases documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases.\nBy specifying the frequency, you’re helping the forecast method better understand the pattern in your data, resulting in more accurate and reliable forecasts.\nLet’s plot the forecasts generated by TimeGPT.\n\ntimegpt.plot(\n    pltr_df, \n    fcst_pltr_df, \n    time_col='date',\n    target_col='Close',\n    max_insample_length=90, \n)\n\n\n\n\nYou can also add uncertainty quantification to your forecasts using the level argument:\n\nfcst_pltr_levels_df = timegpt.forecast(\n    df=pltr_df, h=42, freq='B',\n    time_col='date', target_col='Close',\n    add_history=True,\n    level=[40.66, 90],\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Calling Historical Forecast Endpoint...\n\n\n\ntimegpt.plot(\n    pltr_df, \n    fcst_pltr_levels_df, \n    time_col='date',\n    target_col='Close',\n    level=[40.66, 90],\n)\n\n\n\n\nIf you want to forecast another just change the target_col parameter. Let’s forecast Volume now:\n\nfcst_pltr_df = timegpt.forecast(\n    df=pltr_df, h=14, freq='B',\n    time_col='date', target_col='Volume',\n)\ntimegpt.plot(\n    pltr_df, \n    fcst_pltr_df, \n    time_col='date',\n    max_insample_length=90,\n    target_col='Volume',\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\n\n\nBut what if we want to predict all the time series at once? We can do that reshaping our dataframe. Currently, the dataframe is in wide format (each series is a column), but we need to have them in long format (stacked one each other). We can do it with:\n\npltr_long_df = pd.melt(\n    pltr_df, \n    id_vars=['date'],\n    var_name='series_id'\n)\n\n\npltr_long_df.head()\n\n\n\n\n\n\n\n\ndate\nseries_id\nvalue\n\n\n\n\n0\n2020-09-30\nOpen\n10.00\n\n\n1\n2020-10-01\nOpen\n9.69\n\n\n2\n2020-10-02\nOpen\n9.06\n\n\n3\n2020-10-05\nOpen\n9.43\n\n\n4\n2020-10-06\nOpen\n9.04\n\n\n\n\n\n\n\nThen we just simply call the forecast method specifying the id_col parameter.\n\nfcst_pltr_long_df = timegpt.forecast(\n    df=pltr_long_df, h=14, freq='B',\n    id_col='series_id', time_col='date', target_col='value',\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\nfcst_pltr_long_df.head()\n\n\n\n\n\n\n\n\nseries_id\ndate\nTimeGPT\n\n\n\n\n0\nAdj Close\n2023-09-25\n14.365891\n\n\n1\nAdj Close\n2023-09-26\n14.460796\n\n\n2\nAdj Close\n2023-09-27\n14.413015\n\n\n3\nAdj Close\n2023-09-28\n14.488708\n\n\n4\nAdj Close\n2023-09-29\n14.470786\n\n\n\n\n\n\n\nThen we can forecast the Open series:\n\ntimegpt.plot(\n    pltr_long_df, \n    fcst_pltr_long_df, \n    id_col='series_id',\n    time_col='date',\n    target_col='value',\n    unique_ids=['Open'],\n    max_insample_length=90,\n)\n\n\n\n\n\nAdding extra information\nIn time series forecasting, the variables that we predict are often influenced not just by their past values, but also by other factors or variables. These external variables, known as exogenous variables, can provide vital additional context that can significantly improve the accuracy of our forecasts. One such factor, and the focus of this tutorial, is the company’s revenue. Revenue figures can provide a key indicator of a company’s financial health and growth potential, both of which can heavily influence its stock price. That we can obtain from openbb.\n\nrevenue_pltr = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/openbb/revenue-pltr.csv')\n\n\nrevenue_pltr.tail()\n\n\n\n\n\n\n\n\nfiscalDateEnding\ntotalRevenue\n\n\n\n\n5\n2022-06-30\n473010000.0\n\n\n6\n2022-09-30\n477880000.0\n\n\n7\n2022-12-31\n508624000.0\n\n\n8\n2023-03-31\n525186000.0\n\n\n9\n2023-06-30\n533317000.0\n\n\n\n\n\n\n\nThe first thing we observe in our dataset is that we have information available only up until the end of the first quarter of 2023. Our data is represented in a quarterly frequency, and our goal is to leverage this information to forecast the daily stock prices for the next 14 days beyond this date.\nHowever, to accurately compute such a forecast that includes the revenue as an exogenous variable, we need to have an understanding of the future values of the revenue. This is critical because these future revenue values can significantly influence the stock price.\nSince we’re aiming to predict 14 daily stock prices, we only need to forecast the revenue for the upcoming quarter. This approach allows us to create a cohesive forecasting pipeline where the output of one forecast (revenue) is used as an input to another (stock price), thereby leveraging all available information for the most accurate predictions possible.\n\nfcst_pltr_revenue = timegpt.forecast(revenue_pltr, h=1, time_col='fiscalDateEnding', target_col='totalRevenue')\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\n\n\n\nfcst_pltr_revenue.head()\n\n\n\n\n\n\n\n\nfiscalDateEnding\nTimeGPT\n\n\n\n\n0\n2023-09-30\n547264448\n\n\n\n\n\n\n\nContinuing from where we left off, the next crucial step in our forecasting pipeline is to adjust the frequency of our data to match the stock prices’ frequency, which is represented on a business day basis. To accomplish this, we need to resample both the historical and future forecasted revenue data.\nWe can achieve this using the following code\n\nrevenue_pltr['fiscalDateEnding'] = pd.to_datetime(revenue_pltr['fiscalDateEnding'])\nrevenue_pltr = revenue_pltr.set_index('fiscalDateEnding').resample('B').ffill().reset_index()\n\nIMPORTANT NOTE: It’s crucial to highlight that in this process, we are assigning the same revenue value to all days within the given quarter. This simplification is necessary due to the disparity in granularity between quarterly revenue data and daily stock price data. However, it’s vital to treat this assumption with caution in practical applications. The impact of quarterly revenue figures on daily stock prices can vary significantly within the quarter based on a range of factors, including changing market expectations, other financial news, and events. In this tutorial, we use this assumption to illustrate the process of incorporating exogenous variables into our forecasting model, but in real-world scenarios, a more nuanced approach may be needed, depending on the available data and the specific use case.\nThen we can create the full historic dataset.\n\npltr_revenue_df = pltr_df.merge(revenue_pltr.rename(columns={'fiscalDateEnding': 'date'}))\n\n\npltr_revenue_df.head()\n\n\n\n\n\n\n\n\ndate\nOpen\nHigh\nLow\nClose\nAdj Close\nVolume\nDividends\nStock Splits\ntotalRevenue\n\n\n\n\n0\n2021-03-31\n22.500000\n23.850000\n22.379999\n23.290001\n23.290001\n61458500\n0.0\n0.0\n341234000.0\n\n\n1\n2021-04-01\n23.950001\n23.950001\n22.730000\n23.070000\n23.070000\n51788800\n0.0\n0.0\n341234000.0\n\n\n2\n2021-04-05\n23.780001\n24.450001\n23.340000\n23.440001\n23.440001\n65374300\n0.0\n0.0\n341234000.0\n\n\n3\n2021-04-06\n23.549999\n23.610001\n22.830000\n23.270000\n23.270000\n41933500\n0.0\n0.0\n341234000.0\n\n\n4\n2021-04-07\n23.000000\n23.549999\n22.809999\n22.900000\n22.900000\n32766200\n0.0\n0.0\n341234000.0\n\n\n\n\n\n\n\nTo calculate the dataframe of the future revenue:\n\nhorizon = 14\n\n\nimport numpy as np\n\n\nfuture_df = pd.DataFrame({\n    'date': pd.date_range(pltr_revenue_df['date'].iloc[-1], periods=horizon + 1, freq='B')[-horizon:],\n    'totalRevenue': np.repeat(fcst_pltr_revenue.iloc[0]['TimeGPT'], horizon)\n})\n\n\nfuture_df.head()\n\n\n\n\n\n\n\n\ndate\ntotalRevenue\n\n\n\n\n0\n2023-07-03\n547264448\n\n\n1\n2023-07-04\n547264448\n\n\n2\n2023-07-05\n547264448\n\n\n3\n2023-07-06\n547264448\n\n\n4\n2023-07-07\n547264448\n\n\n\n\n\n\n\nAnd then we can pass the future revenue in the forecast method using the X_df argument. Since the revenue is in the historic dataframe, that information will be used in the model.\n\nfcst_pltr_df = timegpt.forecast(\n    pltr_revenue_df, h=horizon, \n    freq='B',\n    time_col='date', \n    target_col='Close',\n    X_df=future_df,\n)\n\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\n\n\n\ntimegpt.plot(\n    pltr_revenue_df, \n    fcst_pltr_df, \n    id_col='series_id',\n    time_col='date',\n    target_col='Close',\n    max_insample_length=90,\n)\n\n\n\n\nWe can also see the importance of the revenue:\n\ntimegpt.weights_x.plot.barh(x='features', y='weights')\n\n&lt;Axes: ylabel='features'&gt;\n\n\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/distributed_cv_spark.html",
    "href": "docs/how-to-guides/distributed_cv_spark.html",
    "title": "How to on Spark: Cross Validation",
    "section": "",
    "text": "As long as Spark is installed and configured, TimeGPT will be able to use it. If executing on a distributed Spark cluster, make use the nixtlats library is installed across all the workers.\n\n\nTo run the forecasts distributed on Spark, just pass in a Spark DataFrame instead.\nInstantiate TimeGPT class.\n\nfrom nixtlats import TimeGPT\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nUse Spark as an engine.\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/11/09 00:34:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n23/11/09 00:34:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n\n\n\n\n\nurl_df = 'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv'\nspark_df = spark.createDataFrame(pd.read_csv(url_df))\nspark_df.show(5)\n\n                                                                                \n\n\n+---------+-------------------+-----+\n|unique_id|                 ds|    y|\n+---------+-------------------+-----+\n|       BE|2016-12-01 00:00:00| 72.0|\n|       BE|2016-12-01 01:00:00| 65.8|\n|       BE|2016-12-01 02:00:00|59.99|\n|       BE|2016-12-01 03:00:00|50.69|\n|       BE|2016-12-01 04:00:00|52.58|\n+---------+-------------------+-----+\nonly showing top 5 rows\n\n\n\n\nfcst_df = timegpt.cross_validation(spark_df, h=12, n_windows=5, step_size=2)\nfcst_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...                        (4 + 16) / 20]\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...=============&gt;  (19 + 1) / 20]\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n                                                                                \n\n\n+---------+-------------------+-------------------+------------------+\n|unique_id|                 ds|             cutoff|           TimeGPT|\n+---------+-------------------+-------------------+------------------+\n|       FR|2016-12-30 04:00:00|2016-12-30 03:00:00| 44.89374542236328|\n|       FR|2016-12-30 05:00:00|2016-12-30 03:00:00| 46.05792999267578|\n|       FR|2016-12-30 06:00:00|2016-12-30 03:00:00|48.790077209472656|\n|       FR|2016-12-30 07:00:00|2016-12-30 03:00:00| 54.39702606201172|\n|       FR|2016-12-30 08:00:00|2016-12-30 03:00:00| 57.59300231933594|\n+---------+-------------------+-------------------+------------------+\nonly showing top 5 rows\n\n\n\n\n\n\nExogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\nFor example, if you’re forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\nTo incorporate exogenous variables in TimeGPT, you’ll need to pair each point in your time series data with the corresponding external data.\nLet’s see an example.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\nspark_df = spark.createDataFrame(df)\nspark_df.show(5)\n\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|unique_id|                 ds|    y|Exogenous1|Exogenous2|day_0|day_1|day_2|day_3|day_4|day_5|day_6|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|       BE|2016-12-01 00:00:00| 72.0|   61507.0|   71066.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 01:00:00| 65.8|   59528.0|   67311.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 02:00:00|59.99|   58812.0|   67470.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 03:00:00|50.69|   57676.0|   64529.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 04:00:00|52.58|   56804.0|   62773.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\nonly showing top 5 rows\n\n\n\nLet’s call the cross_validation method, adding this information:\n\ntimegpt_cv_ex_vars_df = timegpt.cross_validation(\n    df=spark_df,\n    h=48, \n    level=[80, 90],\n    n_windows=5,\n)\ntimegpt_cv_ex_vars_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...=====================&gt;  (19 + 1) / 20]\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n                                                                                \n\n\n+---------+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n|unique_id|                 ds|             cutoff|           TimeGPT|     TimeGPT-lo-90|     TimeGPT-lo-80|     TimeGPT-hi-80|     TimeGPT-hi-90|\n+---------+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n|       FR|2016-12-21 00:00:00|2016-12-20 23:00:00| 57.46266174316406| 54.32243190002441|54.725050598144534| 60.20027288818359|60.602891586303706|\n|       FR|2016-12-21 01:00:00|2016-12-20 23:00:00|52.549095153808594|50.111817771911625| 50.20576373291016| 54.89242657470703| 54.98637253570556|\n|       FR|2016-12-21 02:00:00|2016-12-20 23:00:00| 49.98523712158203|47.396572181701664| 48.40804647827149|51.562427764892576|  52.5739020614624|\n|       FR|2016-12-21 03:00:00|2016-12-20 23:00:00|   49.146240234375| 46.38533438110352| 46.51724838256836| 51.77523208618164| 51.90714608764648|\n|       FR|2016-12-21 04:00:00|2016-12-20 23:00:00| 47.01085662841797| 42.29354175567627|42.783941421508786|51.237771835327145|51.728171501159665|\n+---------+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\nonly showing top 5 rows\n\n\n\n\nspark.stop()\nGive us a ⭐ on Github"
  },
  {
    "objectID": "docs/how-to-guides/distributed_cv_spark.html#executing-on-spark",
    "href": "docs/how-to-guides/distributed_cv_spark.html#executing-on-spark",
    "title": "How to on Spark: Cross Validation",
    "section": "",
    "text": "To run the forecasts distributed on Spark, just pass in a Spark DataFrame instead.\nInstantiate TimeGPT class.\n\nfrom nixtlats import TimeGPT\n\ntimegpt = TimeGPT(token=os.environ['TIMEGPT_TOKEN'])\n\nUse Spark as an engine.\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/11/09 00:34:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n23/11/09 00:34:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n\n\n\n\n\nurl_df = 'https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv'\nspark_df = spark.createDataFrame(pd.read_csv(url_df))\nspark_df.show(5)\n\n                                                                                \n\n\n+---------+-------------------+-----+\n|unique_id|                 ds|    y|\n+---------+-------------------+-----+\n|       BE|2016-12-01 00:00:00| 72.0|\n|       BE|2016-12-01 01:00:00| 65.8|\n|       BE|2016-12-01 02:00:00|59.99|\n|       BE|2016-12-01 03:00:00|50.69|\n|       BE|2016-12-01 04:00:00|52.58|\n+---------+-------------------+-----+\nonly showing top 5 rows\n\n\n\n\nfcst_df = timegpt.cross_validation(spark_df, h=12, n_windows=5, step_size=2)\nfcst_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...                        (4 + 16) / 20]\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...=============&gt;  (19 + 1) / 20]\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n                                                                                \n\n\n+---------+-------------------+-------------------+------------------+\n|unique_id|                 ds|             cutoff|           TimeGPT|\n+---------+-------------------+-------------------+------------------+\n|       FR|2016-12-30 04:00:00|2016-12-30 03:00:00| 44.89374542236328|\n|       FR|2016-12-30 05:00:00|2016-12-30 03:00:00| 46.05792999267578|\n|       FR|2016-12-30 06:00:00|2016-12-30 03:00:00|48.790077209472656|\n|       FR|2016-12-30 07:00:00|2016-12-30 03:00:00| 54.39702606201172|\n|       FR|2016-12-30 08:00:00|2016-12-30 03:00:00| 57.59300231933594|\n+---------+-------------------+-------------------+------------------+\nonly showing top 5 rows\n\n\n\n\n\n\nExogenous variables or external factors are crucial in time series forecasting as they provide additional information that might influence the prediction. These variables could include holiday markers, marketing spending, weather data, or any other external data that correlate with the time series data you are forecasting.\nFor example, if you’re forecasting ice cream sales, temperature data could serve as a useful exogenous variable. On hotter days, ice cream sales may increase.\nTo incorporate exogenous variables in TimeGPT, you’ll need to pair each point in your time series data with the corresponding external data.\nLet’s see an example.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short-with-ex-vars.csv')\nspark_df = spark.createDataFrame(df)\nspark_df.show(5)\n\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|unique_id|                 ds|    y|Exogenous1|Exogenous2|day_0|day_1|day_2|day_3|day_4|day_5|day_6|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\n|       BE|2016-12-01 00:00:00| 72.0|   61507.0|   71066.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 01:00:00| 65.8|   59528.0|   67311.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 02:00:00|59.99|   58812.0|   67470.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 03:00:00|50.69|   57676.0|   64529.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n|       BE|2016-12-01 04:00:00|52.58|   56804.0|   62773.0|  0.0|  0.0|  0.0|  1.0|  0.0|  0.0|  0.0|\n+---------+-------------------+-----+----------+----------+-----+-----+-----+-----+-----+-----+-----+\nonly showing top 5 rows\n\n\n\nLet’s call the cross_validation method, adding this information:\n\ntimegpt_cv_ex_vars_df = timegpt.cross_validation(\n    df=spark_df,\n    h=48, \n    level=[80, 90],\n    n_windows=5,\n)\ntimegpt_cv_ex_vars_df.show(5)\n\nINFO:nixtlats.timegpt:Validating inputs...=====================&gt;  (19 + 1) / 20]\nINFO:nixtlats.timegpt:Inferred freq: H\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Validating inputs...\nINFO:nixtlats.timegpt:Preprocessing dataframes...\nINFO:nixtlats.timegpt:Inferred freq: H\nWARNING:nixtlats.timegpt:The specified horizon \"h\" exceeds the model horizon. This may lead to less accurate forecasts. Please consider using a smaller horizon.\nINFO:nixtlats.timegpt:Restricting input...\nINFO:nixtlats.timegpt:Calling Forecast Endpoint...\nINFO:nixtlats.timegpt:Validating inputs...\n                                                                                \n\n\n+---------+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n|unique_id|                 ds|             cutoff|           TimeGPT|     TimeGPT-lo-90|     TimeGPT-lo-80|     TimeGPT-hi-80|     TimeGPT-hi-90|\n+---------+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n|       FR|2016-12-21 00:00:00|2016-12-20 23:00:00| 57.46266174316406| 54.32243190002441|54.725050598144534| 60.20027288818359|60.602891586303706|\n|       FR|2016-12-21 01:00:00|2016-12-20 23:00:00|52.549095153808594|50.111817771911625| 50.20576373291016| 54.89242657470703| 54.98637253570556|\n|       FR|2016-12-21 02:00:00|2016-12-20 23:00:00| 49.98523712158203|47.396572181701664| 48.40804647827149|51.562427764892576|  52.5739020614624|\n|       FR|2016-12-21 03:00:00|2016-12-20 23:00:00|   49.146240234375| 46.38533438110352| 46.51724838256836| 51.77523208618164| 51.90714608764648|\n|       FR|2016-12-21 04:00:00|2016-12-20 23:00:00| 47.01085662841797| 42.29354175567627|42.783941421508786|51.237771835327145|51.728171501159665|\n+---------+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\nonly showing top 5 rows\n\n\n\n\nspark.stop()"
  }
]